{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deeplearning - Nasir Hussain - 2021/08/10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39FpsL5cIL_u"
      },
      "source": [
        "# 9 Advanced deep learning for computer vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8cgIlwD3AyK"
      },
      "source": [
        "## 9.3 Modern convnet architecture patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "057LyaNq3FM2"
      },
      "source": [
        "- A model’s “architecture” is the sum of the choices that went into creating it: \n",
        "  - which layers to use, how to configure them, and in what arrangement to connect them\n",
        "- hypothesis space of your model: \n",
        "  - the space of possible functions that gradient descent can search over, parameterized by the model’s weights\n",
        "  - good hypothesis space encodes prior knowledge that you have about the problem at hand and its solution\n",
        "- A good model architecture is one that reduces the size of the search space or otherwise makes it easier to converge to a good point of the search space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY7Ch30e3i7y"
      },
      "source": [
        "### 9.3.1 Modularity, hierarchy, and reuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L0Cml1v4JwT"
      },
      "source": [
        "- make a complex system simpler\n",
        "  - just structure your amorphous soup of complexity into modules\n",
        "  - organize the modules into a hierarchy\n",
        "  - start reusing the same modules in multiple places as appropriate\n",
        "- a deep stack of narrow layers performs better than a shallow stack of large layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOlKA-bj4_0H"
      },
      "source": [
        "##### On the importance of ablation studies in deep learning research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heDExxe95dmH"
      },
      "source": [
        "- Deep learning architectures are often more evolved than designed\n",
        "- ablation studies\n",
        "  - it consist of systematically trying to remove parts of a system—making it simpler—to identify where its performance actually comes from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbwTO4lX5wxF"
      },
      "source": [
        "### 9.3.2 Residual connections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCSOKAC67oJj"
      },
      "source": [
        "- sequential deep learning model\n",
        "\n",
        "  ```\n",
        "  y = f4(f3(f2(f1(x))))\n",
        "  ```\n",
        "  - you may lose information due to noise\n",
        "  - vanishing gradients problem\n",
        "    - when model is too deep due to noise might be possible back-propagation might not work\n",
        "  - fix\n",
        "    - just force each function in the chain to be nondestructive—to retain a noiseless version of the information contained in the previous input. The easiest way to implement this is to use a residual connection\n",
        "  - A residual connection in pseudocode\n",
        "\n",
        "    ```\n",
        "    x = ...\n",
        "    residual = x\n",
        "    x = block(x)\n",
        "    x = add([x, residual])\n",
        "    ```\n",
        "    - output and input should have same shape\n",
        "    - for conv2D use 1*1 conv2D\n",
        "    - for maxpoling use stride"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OztT_Ael-INQ"
      },
      "outputs": [],
      "source": [
        "# Listing 9.2 Residual block where the number of filters changes\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        " \n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
        "residual = x\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "residual = layers.Conv2D(64, 1)(residual)\n",
        "x = layers.add([x, residual]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XQJwzyV_-ivt"
      },
      "outputs": [],
      "source": [
        "# Listing 9.3 Case where the target block includes a max pooling layer\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
        "residual = x\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
        "residual = layers.Conv2D(64, 1, strides=2)(residual)\n",
        "x = layers.add([x, residual])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTcrPWGR--CN",
        "outputId": "99253a60-e073-463a-d244-6c6174c6ea0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 32, 32, 3)    0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 32)   896         ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 32)   9248        ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 32)  0           ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 32)   128         ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 16, 32)   0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 64)   18496       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 64)   36928       ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)    0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 8, 8, 64)     2112        ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 8, 8, 64)     0           ['max_pooling2d_2[0][0]',        \n",
            "                                                                  'conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 8, 8, 128)    73856       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 8, 8, 128)    147584      ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 8, 8, 128)    8320        ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 8, 8, 128)    0           ['conv2d_13[0][0]',              \n",
            "                                                                  'conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 128)         0           ['add_4[0][0]']                  \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            129         ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 297,697\n",
            "Trainable params: 297,697\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# a simple convnet structured into a series of blocks, \n",
        "# each made of two convolution layers and one optional max pooling layer, \n",
        "# with a residual connec\u0002tion around each block\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        " \n",
        "def residual_block(x, filters, pooling=False):\n",
        "  residual = x\n",
        "  x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "  x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "  if pooling:\n",
        "    x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
        "    residual = layers.Conv2D(filters, 1, strides=2)(residual)\n",
        "  elif filters != residual.shape[-1]:\n",
        "    residual = layers.Conv2D(filters, 1)(residual)\n",
        "  x = layers.add([x, residual])\n",
        "  return x\n",
        "\n",
        "x = residual_block(x, filters=32, pooling=True)\n",
        "x = residual_block(x, filters=64, pooling=True)\n",
        "x = residual_block(x, filters=128, pooling=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LskobhxCAapc"
      },
      "source": [
        "### 9.3.3 Batch normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWx2fUotEpI-"
      },
      "source": [
        "- Normalization\n",
        "  - methods that seek to make different samples seen by a machine learning model more similar to each other, which helps the model learn and generalize well to new data.\n",
        "  - common form of data normalization\n",
        "    - centering the data on zero by subtracting the mean from the data, and giving the data a unit standard deviation by dividing the data by its standard deviation\n",
        "\n",
        "      ```\n",
        "      normalized_data = (data - np.mean(data, axis=...)) / np.std(data, axis=...)\n",
        "      ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKmXSE68FjE4"
      },
      "source": [
        "- Batch normalization\n",
        "  - a type of layer ( BatchNormalization in Keras)\n",
        "  - it can adaptively normalize data even as the mean and variance change over time during training. \n",
        "    - During training, it uses the mean and variance of the current batch of data to normalize samples\n",
        "    - during inference, it uses an exponential moving average of the batch-wise mean and variance of the data seen during training\n",
        "  - main effect of batch normalization appears to be that it helps with gradient propagation\n",
        "  - The BatchNormalization layer can be used after any layer— Dense , Conv2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qryQ63_qG7BA"
      },
      "outputs": [],
      "source": [
        "# Listing 9.4 How not to use batch normalization\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqsQlNJZG-JN"
      },
      "outputs": [],
      "source": [
        "# Listing 9.5 How to use batch normalization: the activation comes last\n",
        "x = layers.Conv2D(32, 3, use_bias=False)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb_fjYhDHV5s"
      },
      "source": [
        "### 9.3.4 Depthwise separable convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZJqjcfEM6KH"
      },
      "source": [
        "- depthwise separable convolution layer\n",
        "  - drop-in replacement for Conv2D\n",
        "  - make model \n",
        "    - smaller\n",
        "    - leaner\n",
        "    - cause it to perform a few percentage points better on its task\n",
        "  - This layer performs a spatial convolution on each channel of its input independently, before mixing output channels via a pointwise convolution\n",
        "  - equivalent to separating the learning of spatial features and the learning of channel-wise features.\n",
        "  - assumes that spatial locations in intermediate activations are highly correlated, but different channels are highly independent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EldpTJ1pPj9y"
      },
      "source": [
        "- Depthwise separable convolution \n",
        "  - requires significantly fewer parameters, involves fewer computations compared to regular convolution, while having comparable representational power. \n",
        "  - It results in smaller models that converge faster and are less prone to overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2BCGy2SQt4W"
      },
      "source": [
        "##### The co-evolution of hardware, software, and algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zCOobuzQrm9"
      },
      "source": [
        "-  depthwise separable convolutions remains a good idea even if it does not result in a speedup: \n",
        "  - their lower parameter count means that you are less at risk of overfitting\n",
        "  - their assumption that channels should be uncorrelated leads to faster model convergence and more robust representations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meR7-IQzHodH"
      },
      "source": [
        "### 9.3.5 Putting it together: A mini Xception-like model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfiDqcQgH0PA"
      },
      "source": [
        "- convnet architecture principles\n",
        "  - Your model should be organized into repeated blocks of layers, usually made of multiple convolution layers and a max pooling layer.\n",
        "  - The number of filters in your layers should increase as the size of the spatial feature maps decreases.\n",
        "  - Deep and narrow is better than broad and shallow.\n",
        "  - Introducing residual connections around blocks of layers helps you train deeper networks.\n",
        "  - It can be beneficial to introduce batch normalization layers after your convolution layers.\n",
        "  - It can be beneficial to replace Conv2D layers with SeparableConv2D layers, which are more parameter-efficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA4DLYaUI8XD"
      },
      "source": [
        "##### Cats vs Dogs CNN (architecture principles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "Z-QfbKdSLCWx",
        "outputId": "973e6cfa-c48d-4ca7-dd32-4c818191a5bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28896aad-d12f-4520-97bd-02a8d71c9deb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28896aad-d12f-4520-97bd-02a8d71c9deb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            " 97% 786M/812M [00:04<00:00, 200MB/s]\n",
            "100% 812M/812M [00:04<00:00, 199MB/s]\n"
          ]
        }
      ],
      "source": [
        "# piece of code to download kaggle data directly to colab\n",
        "# upload kaggle json file on the colab\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "# make kaggle directory\n",
        "!mkdir ~/.kaggle\n",
        "# move kaggle file to newly created folder\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "# chnage permissions for file created\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# Downlaod data from kaggle\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zuu6WUFSLAdE"
      },
      "outputs": [],
      "source": [
        "# unzip downloaded data\n",
        "!unzip -qq dogs-vs-cats.zip\n",
        "!unzip -qq train.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "brM24luWK9IK"
      },
      "outputs": [],
      "source": [
        "# Copying images to training, validation, and test directories\n",
        "\n",
        "# imports\n",
        "import os, shutil, pathlib\n",
        "\n",
        "# path to complete data set \n",
        "original_dir = pathlib.Path(\"train\")\n",
        "# path to smaller data set\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "# function to get images from complete set and save in subset\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "  # loop over cat and dog category\n",
        "  for category in (\"cat\", \"dog\"):\n",
        "    # path to new directory\n",
        "    dir = new_base_dir / subset_name / category\n",
        "    # make new directories\n",
        "    os.makedirs(dir)\n",
        "    # range of files names\n",
        "    fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "    for fname in fnames:\n",
        "      # copy files from source to target\n",
        "      shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        " \n",
        "# call sfor train, validation and test set\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK6ABxCeK2SJ",
        "outputId": "0aca9d21-f048-4869-9999-3d13b5a78f3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "#  Using image_dataset_from_directory to read images\n",
        "  # image_dataset_from_directory(directory) will list the subdirectories of directory\n",
        "  # index the image files in each subdirectory\n",
        "  # create and return a tf.data.Dataset object \n",
        "    # configured to read these files, \n",
        "    # shuffle them\n",
        "    # decode them to tensors\n",
        "    # resize them to a shared size\n",
        "    # and pack them into batches.\n",
        "\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        " \n",
        "# create datasets\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    # path of the directory\n",
        "    new_base_dir / \"train\",\n",
        "    # reshape images to said size\n",
        "    image_size=(180, 180),\n",
        "    # batch size / 32 samples per batch\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kAenzR4KzAz",
        "outputId": "4d908237-28cc-4df4-a5a6-7e1d78db4cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bathces of train_dataset :  62\n",
            "train data batch shape: (32, 180, 180, 3)\n",
            "train labels batch shape: (32,)\n",
            "bathces of validation_dataset :  31\n",
            "validation data batch shape: (32, 180, 180, 3)\n",
            "validation labels batch shape: (32,)\n",
            "bathces of test_dataset :  62\n",
            "test data batch shape: (32, 180, 180, 3)\n",
            "test labels batch shape: (32,)\n"
          ]
        }
      ],
      "source": [
        "# Displaying the shapes of the data and labels yielded by the Dataset\n",
        "for i, element in enumerate(train_dataset):\n",
        "  pass\n",
        "print(\"bathces of train_dataset : \",i)\n",
        "\n",
        "for train_data_batch, train_labels_batch in train_dataset:\n",
        "  print(\"train data batch shape:\", train_data_batch.shape)\n",
        "  print(\"train labels batch shape:\", train_labels_batch.shape)\n",
        "  break\n",
        "\n",
        "for i, element in enumerate(validation_dataset):\n",
        "  pass\n",
        "print(\"bathces of validation_dataset : \",i)\n",
        "for validation_data_batch, validation_labels_batch in validation_dataset:\n",
        "  print(\"validation data batch shape:\", validation_data_batch.shape)\n",
        "  print(\"validation labels batch shape:\", validation_labels_batch.shape)\n",
        "  break\n",
        "\n",
        "for i, element in enumerate(test_dataset):\n",
        "  pass\n",
        "print(\"bathces of test_dataset : \",i)\n",
        "for test_data_batch, test_labels_batch in test_dataset:\n",
        "  print(\"test data batch shape:\", test_data_batch.shape)\n",
        "  print(\"test labels batch shape:\", test_labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ajagKlSeJZ4U"
      },
      "outputs": [],
      "source": [
        "# Define a data augmentation stage to add to an image mode\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "     layers.RandomFlip(\"horizontal\"),\n",
        "     layers.RandomRotation(0.1),\n",
        "     layers.RandomZoom(0.2),\n",
        "    ]\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5U_r-sOnIDLq"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
        "\n",
        "for size in [32, 64, 128, 256, 512]:\n",
        "  residual = x\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "  x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "  x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "  x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "  residual = layers.Conv2D(size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
        "  x = layers.add([x, residual])\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWCZozMOLq_6",
        "outputId": "f0948280-6412-4587-fece-ea53d67d1364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 180, 180, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 180, 180, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 180, 180, 3)  0           ['sequential[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 176, 176, 32  2400        ['rescaling[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 176, 176, 32  128        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 176, 176, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d (SeparableCon  (None, 176, 176, 32  1312       ['activation[0][0]']             \n",
            " v2D)                           )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 176, 176, 32  128        ['separable_conv2d[0][0]']       \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 176, 176, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d_1 (SeparableC  (None, 176, 176, 32  1312       ['activation_1[0][0]']           \n",
            " onv2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 88, 88, 32)   0           ['separable_conv2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 88, 88, 32)   1024        ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 88, 88, 32)   0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 88, 88, 32)  128         ['add[0][0]']                    \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 88, 88, 32)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_2 (SeparableC  (None, 88, 88, 64)  2336        ['activation_2[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 88, 88, 64)  256         ['separable_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 88, 88, 64)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_3 (SeparableC  (None, 88, 88, 64)  4672        ['activation_3[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 44, 44, 64)  0           ['separable_conv2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 44, 44, 64)   2048        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 44, 44, 64)   0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 44, 44, 64)  256         ['add_1[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 44, 44, 64)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_4 (SeparableC  (None, 44, 44, 128)  8768       ['activation_4[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 44, 44, 128)  512        ['separable_conv2d_4[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 44, 44, 128)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_5 (SeparableC  (None, 44, 44, 128)  17536      ['activation_5[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 22, 22, 128)  0          ['separable_conv2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 22, 22, 128)  8192        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 22, 22, 128)  0           ['max_pooling2d_2[0][0]',        \n",
            "                                                                  'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 22, 22, 128)  512        ['add_2[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 22, 22, 128)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_6 (SeparableC  (None, 22, 22, 256)  33920      ['activation_6[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 22, 22, 256)  1024       ['separable_conv2d_6[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 22, 22, 256)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_7 (SeparableC  (None, 22, 22, 256)  67840      ['activation_7[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 11, 11, 256)  0          ['separable_conv2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 11, 11, 256)  32768       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 11, 11, 256)  0           ['max_pooling2d_3[0][0]',        \n",
            "                                                                  'conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 11, 11, 256)  1024       ['add_3[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 11, 11, 256)  0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_8 (SeparableC  (None, 11, 11, 512)  133376     ['activation_8[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 11, 11, 512)  2048       ['separable_conv2d_8[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 11, 11, 512)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_9 (SeparableC  (None, 11, 11, 512)  266752     ['activation_9[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 512)   0           ['separable_conv2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 6, 6, 512)    131072      ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 6, 6, 512)    0           ['max_pooling2d_4[0][0]',        \n",
            "                                                                  'conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 512)         0           ['add_4[0][0]']                  \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 512)          0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            513         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 721,857\n",
            "Trainable params: 718,849\n",
            "Non-trainable params: 3,008\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IdTpLIyBLoah"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"rmsprop\",\n",
        "    metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMhdElWyKgb8",
        "outputId": "a65176ea-c111-496b-e5fa-c86d1736e596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 43s 422ms/step - loss: 0.7076 - accuracy: 0.5645 - val_loss: 0.6989 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.6536 - accuracy: 0.6145 - val_loss: 0.6991 - val_accuracy: 0.5010\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 26s 408ms/step - loss: 0.6488 - accuracy: 0.6220 - val_loss: 0.6999 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 26s 408ms/step - loss: 0.6295 - accuracy: 0.6445 - val_loss: 0.6963 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 26s 412ms/step - loss: 0.6150 - accuracy: 0.6545 - val_loss: 0.7038 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.5897 - accuracy: 0.6905 - val_loss: 0.8558 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 26s 412ms/step - loss: 0.5744 - accuracy: 0.6985 - val_loss: 0.7555 - val_accuracy: 0.5420\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.5514 - accuracy: 0.7275 - val_loss: 1.0639 - val_accuracy: 0.5110\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 26s 410ms/step - loss: 0.5198 - accuracy: 0.7545 - val_loss: 1.2484 - val_accuracy: 0.5640\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 26s 416ms/step - loss: 0.5087 - accuracy: 0.7545 - val_loss: 1.1222 - val_accuracy: 0.5760\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 26s 410ms/step - loss: 0.4820 - accuracy: 0.7665 - val_loss: 0.5865 - val_accuracy: 0.7140\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 26s 417ms/step - loss: 0.4867 - accuracy: 0.7770 - val_loss: 0.7338 - val_accuracy: 0.6860\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.4695 - accuracy: 0.7790 - val_loss: 0.6234 - val_accuracy: 0.7200\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 26s 410ms/step - loss: 0.4527 - accuracy: 0.7885 - val_loss: 0.4893 - val_accuracy: 0.7540\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 26s 414ms/step - loss: 0.4529 - accuracy: 0.7865 - val_loss: 0.5947 - val_accuracy: 0.6770\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 26s 406ms/step - loss: 0.4213 - accuracy: 0.8030 - val_loss: 0.6436 - val_accuracy: 0.6950\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 26s 410ms/step - loss: 0.4303 - accuracy: 0.8095 - val_loss: 0.5517 - val_accuracy: 0.7290\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 27s 419ms/step - loss: 0.4148 - accuracy: 0.8130 - val_loss: 0.4982 - val_accuracy: 0.7720\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 26s 413ms/step - loss: 0.4089 - accuracy: 0.8110 - val_loss: 0.7221 - val_accuracy: 0.7040\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 26s 416ms/step - loss: 0.3904 - accuracy: 0.8335 - val_loss: 1.2500 - val_accuracy: 0.6110\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.3897 - accuracy: 0.8390 - val_loss: 0.9208 - val_accuracy: 0.6450\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 26s 409ms/step - loss: 0.3921 - accuracy: 0.8255 - val_loss: 0.6283 - val_accuracy: 0.7240\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 26s 416ms/step - loss: 0.3597 - accuracy: 0.8425 - val_loss: 0.5269 - val_accuracy: 0.7320\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 26s 413ms/step - loss: 0.3633 - accuracy: 0.8400 - val_loss: 0.6709 - val_accuracy: 0.7360\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.3275 - accuracy: 0.8545 - val_loss: 0.7638 - val_accuracy: 0.7620\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 27s 416ms/step - loss: 0.3246 - accuracy: 0.8625 - val_loss: 0.5399 - val_accuracy: 0.7510\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 26s 410ms/step - loss: 0.3451 - accuracy: 0.8400 - val_loss: 0.9436 - val_accuracy: 0.6980\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 27s 419ms/step - loss: 0.3129 - accuracy: 0.8650 - val_loss: 0.7629 - val_accuracy: 0.7340\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.3157 - accuracy: 0.8655 - val_loss: 0.6699 - val_accuracy: 0.7210\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 26s 409ms/step - loss: 0.3002 - accuracy: 0.8705 - val_loss: 0.5068 - val_accuracy: 0.7740\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 26s 409ms/step - loss: 0.2874 - accuracy: 0.8725 - val_loss: 0.5107 - val_accuracy: 0.8000\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 27s 418ms/step - loss: 0.2801 - accuracy: 0.8800 - val_loss: 3.0477 - val_accuracy: 0.5060\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 26s 404ms/step - loss: 0.2846 - accuracy: 0.8800 - val_loss: 0.6319 - val_accuracy: 0.7000\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 27s 417ms/step - loss: 0.2742 - accuracy: 0.8905 - val_loss: 0.4550 - val_accuracy: 0.8290\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 27s 421ms/step - loss: 0.2615 - accuracy: 0.8890 - val_loss: 0.4027 - val_accuracy: 0.8330\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 26s 414ms/step - loss: 0.2758 - accuracy: 0.8800 - val_loss: 0.9495 - val_accuracy: 0.6790\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 27s 421ms/step - loss: 0.2435 - accuracy: 0.9000 - val_loss: 0.7843 - val_accuracy: 0.7540\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.2443 - accuracy: 0.8950 - val_loss: 0.4530 - val_accuracy: 0.8310\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 26s 407ms/step - loss: 0.2435 - accuracy: 0.8970 - val_loss: 0.6772 - val_accuracy: 0.7830\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 27s 420ms/step - loss: 0.2396 - accuracy: 0.9045 - val_loss: 0.5278 - val_accuracy: 0.8140\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 28s 438ms/step - loss: 0.2341 - accuracy: 0.8990 - val_loss: 0.3773 - val_accuracy: 0.8630\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 27s 416ms/step - loss: 0.2352 - accuracy: 0.9000 - val_loss: 4.6317 - val_accuracy: 0.5210\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 26s 414ms/step - loss: 0.2198 - accuracy: 0.9095 - val_loss: 1.2369 - val_accuracy: 0.6930\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 26s 412ms/step - loss: 0.2241 - accuracy: 0.9090 - val_loss: 0.3573 - val_accuracy: 0.8660\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.2166 - accuracy: 0.9105 - val_loss: 0.6521 - val_accuracy: 0.7840\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 26s 416ms/step - loss: 0.2107 - accuracy: 0.9105 - val_loss: 0.3667 - val_accuracy: 0.8600\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 26s 414ms/step - loss: 0.2170 - accuracy: 0.9100 - val_loss: 0.7077 - val_accuracy: 0.7840\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 27s 422ms/step - loss: 0.1989 - accuracy: 0.9180 - val_loss: 0.4741 - val_accuracy: 0.8370\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 26s 405ms/step - loss: 0.1988 - accuracy: 0.9155 - val_loss: 0.7462 - val_accuracy: 0.7910\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.1956 - accuracy: 0.9200 - val_loss: 0.6715 - val_accuracy: 0.7510\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 27s 417ms/step - loss: 0.2021 - accuracy: 0.9190 - val_loss: 0.4031 - val_accuracy: 0.8550\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 27s 417ms/step - loss: 0.1829 - accuracy: 0.9260 - val_loss: 0.6580 - val_accuracy: 0.7940\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.1695 - accuracy: 0.9395 - val_loss: 1.9527 - val_accuracy: 0.6280\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.2097 - accuracy: 0.9145 - val_loss: 0.3403 - val_accuracy: 0.8680\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 26s 412ms/step - loss: 0.1827 - accuracy: 0.9240 - val_loss: 0.5090 - val_accuracy: 0.8300\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 27s 420ms/step - loss: 0.1558 - accuracy: 0.9400 - val_loss: 0.8140 - val_accuracy: 0.7660\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 26s 405ms/step - loss: 0.1845 - accuracy: 0.9230 - val_loss: 0.4800 - val_accuracy: 0.7880\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 27s 418ms/step - loss: 0.1871 - accuracy: 0.9180 - val_loss: 0.4441 - val_accuracy: 0.8430\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 26s 416ms/step - loss: 0.1770 - accuracy: 0.9315 - val_loss: 0.7020 - val_accuracy: 0.7730\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 27s 417ms/step - loss: 0.1622 - accuracy: 0.9355 - val_loss: 0.6380 - val_accuracy: 0.8000\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.1585 - accuracy: 0.9385 - val_loss: 0.4340 - val_accuracy: 0.8500\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 26s 413ms/step - loss: 0.1660 - accuracy: 0.9355 - val_loss: 0.6888 - val_accuracy: 0.8230\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 26s 414ms/step - loss: 0.1564 - accuracy: 0.9440 - val_loss: 0.4314 - val_accuracy: 0.8450\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 27s 420ms/step - loss: 0.1627 - accuracy: 0.9350 - val_loss: 0.4360 - val_accuracy: 0.8540\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 26s 410ms/step - loss: 0.1369 - accuracy: 0.9485 - val_loss: 0.8351 - val_accuracy: 0.7910\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 27s 417ms/step - loss: 0.1276 - accuracy: 0.9505 - val_loss: 1.3909 - val_accuracy: 0.6630\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 27s 421ms/step - loss: 0.1442 - accuracy: 0.9395 - val_loss: 0.8831 - val_accuracy: 0.7770\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 26s 406ms/step - loss: 0.1403 - accuracy: 0.9430 - val_loss: 0.4033 - val_accuracy: 0.8520\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 27s 418ms/step - loss: 0.1504 - accuracy: 0.9435 - val_loss: 0.6145 - val_accuracy: 0.8200\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 26s 412ms/step - loss: 0.1473 - accuracy: 0.9430 - val_loss: 1.1389 - val_accuracy: 0.7290\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 26s 416ms/step - loss: 0.1350 - accuracy: 0.9445 - val_loss: 0.4575 - val_accuracy: 0.8510\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 27s 417ms/step - loss: 0.1541 - accuracy: 0.9375 - val_loss: 0.3740 - val_accuracy: 0.8810\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 27s 419ms/step - loss: 0.1354 - accuracy: 0.9525 - val_loss: 0.4163 - val_accuracy: 0.8750\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 26s 414ms/step - loss: 0.1422 - accuracy: 0.9430 - val_loss: 1.2006 - val_accuracy: 0.7550\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.1217 - accuracy: 0.9510 - val_loss: 0.5166 - val_accuracy: 0.8560\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 26s 410ms/step - loss: 0.1346 - accuracy: 0.9455 - val_loss: 0.8461 - val_accuracy: 0.7900\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 27s 416ms/step - loss: 0.1459 - accuracy: 0.9435 - val_loss: 0.7375 - val_accuracy: 0.8080\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 27s 418ms/step - loss: 0.1318 - accuracy: 0.9390 - val_loss: 0.4112 - val_accuracy: 0.8710\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.1364 - accuracy: 0.9455 - val_loss: 0.5528 - val_accuracy: 0.8450\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.1159 - accuracy: 0.9565 - val_loss: 0.5537 - val_accuracy: 0.8390\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.1179 - accuracy: 0.9540 - val_loss: 1.1026 - val_accuracy: 0.7340\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.1280 - accuracy: 0.9500 - val_loss: 0.4457 - val_accuracy: 0.8720\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.1089 - accuracy: 0.9590 - val_loss: 0.9875 - val_accuracy: 0.7430\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.1219 - accuracy: 0.9570 - val_loss: 0.3714 - val_accuracy: 0.8880\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.1163 - accuracy: 0.9540 - val_loss: 0.3476 - val_accuracy: 0.8720\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 26s 407ms/step - loss: 0.1273 - accuracy: 0.9475 - val_loss: 0.4376 - val_accuracy: 0.8600\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 26s 412ms/step - loss: 0.1359 - accuracy: 0.9445 - val_loss: 0.3811 - val_accuracy: 0.8820\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 26s 411ms/step - loss: 0.1161 - accuracy: 0.9560 - val_loss: 0.8810 - val_accuracy: 0.8040\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 27s 418ms/step - loss: 0.1207 - accuracy: 0.9575 - val_loss: 0.4169 - val_accuracy: 0.8740\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 27s 415ms/step - loss: 0.1004 - accuracy: 0.9620 - val_loss: 1.2491 - val_accuracy: 0.7850\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 26s 414ms/step - loss: 0.1116 - accuracy: 0.9605 - val_loss: 0.4278 - val_accuracy: 0.8810\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.0908 - accuracy: 0.9600 - val_loss: 0.4377 - val_accuracy: 0.8810\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 26s 410ms/step - loss: 0.1193 - accuracy: 0.9520 - val_loss: 0.4580 - val_accuracy: 0.8850\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 26s 415ms/step - loss: 0.1091 - accuracy: 0.9590 - val_loss: 0.2971 - val_accuracy: 0.9140\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 26s 413ms/step - loss: 0.1070 - accuracy: 0.9580 - val_loss: 0.3678 - val_accuracy: 0.8880\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 26s 412ms/step - loss: 0.1163 - accuracy: 0.9530 - val_loss: 0.4211 - val_accuracy: 0.8870\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 26s 412ms/step - loss: 0.0969 - accuracy: 0.9645 - val_loss: 0.4125 - val_accuracy: 0.8770\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 27s 417ms/step - loss: 0.1060 - accuracy: 0.9590 - val_loss: 0.4666 - val_accuracy: 0.8760\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 26s 414ms/step - loss: 0.1029 - accuracy: 0.9605 - val_loss: 0.5263 - val_accuracy: 0.8570\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 27s 419ms/step - loss: 0.1055 - accuracy: 0.9555 - val_loss: 0.5489 - val_accuracy: 0.8280\n"
          ]
        }
      ],
      "source": [
        "# Training the regularized convnet\n",
        "callbacks = [\n",
        "  keras.callbacks.ModelCheckpoint(\n",
        "  filepath=\"cats_vs_dogs_small_with_architecture_principles.keras\",\n",
        "  save_best_only=True,\n",
        "  monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "  train_dataset,\n",
        "  epochs=100,\n",
        "  validation_data=validation_dataset,\n",
        "  callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "bBqiF4tBMCSM",
        "outputId": "802aed1e-5fca-428c-fa31-4e747f908391"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Displaying curves of loss and accuracy during training\n",
        "import matplotlib.pyplot as plt\n",
        "accuracy = history.history[\"accuracy\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc7D1hxHMKg_",
        "outputId": "4db76429-db6f-4e74-e43d-04734d86b6e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 3s 41ms/step - loss: 0.3739 - accuracy: 0.8975\n",
            "Test accuracy: 0.897\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model on the test set\n",
        "test_model = keras.models.load_model(\"cats_vs_dogs_small_with_architecture_principles.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBL5xkNOTvNo"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DeepLearning_book_9_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
