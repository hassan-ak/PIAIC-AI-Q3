{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deeplearning - Anees Ahmad - 2020/03/08"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1vv3o4Mwcq-"
      },
      "source": [
        "# 8 Introduction to deep learning for computer vision\n",
        "- convolutional neural networks\n",
        "  - convnets\n",
        "  - used universally in computer vision applications\n",
        "  - image-classification problems\n",
        "  - small training datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nqVyLGiQLMe"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ_KmAGl8SfU"
      },
      "source": [
        "## 8.1 Introduction to convnets\n",
        "- a basic convnet\n",
        "  - a stack of Conv2D and MaxPooling2D layers.\n",
        "  - convnet takes as input tensors of shape `(image_height, image_width,image_channels)`\n",
        "\n",
        "- build the model using the Functional API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PLLKCNi0-iSZ"
      },
      "outputs": [],
      "source": [
        "# Listing 8.1 Instantiating a small convnet\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "# define the input shape\n",
        "# as we are dealing with MNIST data we know it is a 28*28 pixels graysacale image\n",
        "inputs = keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "# a convent is stacks of Conv2D and MaxPooling2D layers\n",
        "# filter is actually the nodes/channels, karnel_size is the weight\n",
        "# same layer can be created using sequential class as follows\n",
        "  # model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# pool size defines the factor with which it scale down\n",
        "  # model.add(layers.MaxPooling2D((2, 2)))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlvyIHdHLiom"
      },
      "source": [
        "- Output of Conv2D and MaxPooling2D layer\n",
        "  - rank-3 tensor of shape `(height, width, channels)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "smGXrz65LcRU"
      },
      "outputs": [],
      "source": [
        "# next we have stacks of Dense layer, whihc actually takes 1D tensor as input\n",
        "# need to flattern the output of last Conv28 Layer\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIyur_dqCrg8",
        "outputId": "d88f9f0d-919e-40b7-d399-36a207c3e895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                11530     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104,202\n",
            "Trainable params: 104,202\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Listing 8.2 Displaying the modelâ€™s summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W3oBexaPFuo",
        "outputId": "7724c174-09a4-4418-aecd-2582c1420a77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 10s 9ms/step - loss: 0.1553 - accuracy: 0.9526\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0436 - accuracy: 0.9866\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0298 - accuracy: 0.9909\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0227 - accuracy: 0.9929\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.0176 - accuracy: 0.9944\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f91d042f110>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Listing 8.3 Training the convnet on MNIST images\n",
        "from tensorflow.keras.datasets import mnist\n",
        " \n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQi_N352PTwC",
        "outputId": "336dddc8-4d98-4c35-e088-085887ba0120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9900\n",
            "Test accuracy: 0.990\n"
          ]
        }
      ],
      "source": [
        "# Listing 8.4 Evaluating the convnet\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW5B2HZCPnDX"
      },
      "source": [
        "- With out convents we have an accuracy of 97.8%\n",
        "- With convents we have accuracy of 99.1%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Sp2bPHQON-"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DeepLearning-book-8.1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
