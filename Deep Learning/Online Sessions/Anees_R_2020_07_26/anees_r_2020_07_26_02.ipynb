{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Learning - Anees Ahmad - 2020/07/26"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVIqKsm30-dr"
      },
      "source": [
        "# 12 Generative deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObPQ1X_F5Z84"
      },
      "source": [
        "## 12.5 Introduction to generative adversarial networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfzdggwAF-w2"
      },
      "source": [
        "- a forger network and an expert network, each being trained to best the other\n",
        "- Two parts\n",
        "  - Generator network\n",
        "    - Takes as input a random vector (a random point in the latent space), and decodes it into a synthetic image\n",
        "  - Discriminator network (or adversary)\n",
        "    - Takes as input an image (real or synthetic), and predicts whether the image came from the training set or was created by the generator network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WquRcI5GokZ"
      },
      "source": [
        "### 12.5.1 A schematic GAN implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwHb7EftG7vX"
      },
      "source": [
        "- A generator network maps vectors of shape (latent_dim,) to images of shap (64, 64, 3).\n",
        "- A discriminator network maps images of shape (64, 64, 3) to a binary score estimating the probability that the image is real.\n",
        "- A gan network chains the generator and the discriminator together: gan(x) =\n",
        "discriminator(generator(x)) . Thus, this gan network maps latent space vectors to the discriminator’s assessment of the realism of these latent vectors as decoded by the generator.\n",
        "- We train the discriminator using examples of real and fake images along with “real”/“fake” labels, just as we train any regular image-classification model.\n",
        "- To train the generator, we use the gradients of the generator’s weights with regard to the loss of the gan model. This means that at every step, we move the weights of the generator in a direction that makes the discriminator more likely to classify as “real” the images decoded by the generator. In other words, we train the generator to fool the discriminator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIsBimDsHRPm"
      },
      "source": [
        "### 12.5.2 A bag of tricks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IzW3B_SH7PN"
      },
      "source": [
        "- We use strides instead of pooling for downsampling feature maps in the discriminator, just like we did in our VAE encoder.\n",
        "- We sample points from the latent space using a normal distribution (Gaussian distribution), not a uniform distribution.\n",
        "- Stochasticity is good for inducing robustness. Because GAN training results in a dynamic equilibrium, GANs are likely to get stuck in all sorts of ways. Introducing randomness during training helps prevent this. We introduce randomness by adding random noise to the labels for the discriminator.\n",
        "- Sparse gradients can hinder GAN training. In deep learning, sparsity is often a desirable property, but not in GANs. Two things can induce gradient sparsity:\n",
        "  - max pooling operations and relu activations.\n",
        "- Instead of max pooling, we recommend using strided convolutions for downsampling, and we recommend using a LeakyReLU layer instead of a relu activation. It’s similar to relu , but it relaxes sparsity constraints by allowing small negative activation values.\n",
        "- In generated images, it’s common to see checkerboard artifacts caused by unequal coverage of the pixel space in the generator. To fix this, we use a kernel size that’s divisible by the stride size whenever we use a strided Conv2DTranspose or Conv2D in both the generator and the discriminator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpd9ww45KuFN"
      },
      "source": [
        "### 12.5.3 Getting our hands on the CelebA dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYl7k1UwK0L8",
        "outputId": "fabbfd53-90d6-405d-e23a-0aa04686982e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\n",
            "To: /content/celeba_gan/data.zip\n",
            "100% 1.44G/1.44G [00:14<00:00, 96.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Listing 12.30 Getting the CelebA data\n",
        "\n",
        "!mkdir celeba_gan \n",
        "!gdown --id 1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684 -O celeba_gan/data.zip\n",
        "!unzip -qq celeba_gan/data.zip -d celeba_gan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pVlkdgjLAQ1",
        "outputId": "90e5a9e3-9226-496c-8733-1918a7ff5427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 202599 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# Listing 12.31 Creating a dataset from a directory of images\n",
        "from tensorflow import keras\n",
        "dataset = keras.utils.image_dataset_from_directory(\n",
        "    \"celeba_gan\",\n",
        "    label_mode=None,\n",
        "    image_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    smart_resize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eikpc4QMLHeS"
      },
      "outputs": [],
      "source": [
        "# Listing 12.32 Rescaling the images\n",
        "\n",
        "dataset = dataset.map(lambda x: x / 255.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "Fka0o4jMLLtb",
        "outputId": "aeb1dd1b-37e6-4103-a7a1-a0885e999491"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Listing 12.33 Displaying the first image\n",
        "import matplotlib.pyplot as plt\n",
        "for x in dataset:\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJcCwmMELTqQ"
      },
      "source": [
        "### 12.5.4 The discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5McsaVjvLVKB"
      },
      "outputs": [],
      "source": [
        "# Listing 12.34 The GAN discriminator network\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(64, 64, 3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUWFPPnqLiH6",
        "outputId": "e2bc0740-cda0-4328-ce09-06c0425ad6ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        3136      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         262272    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 8193      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 404,801\n",
            "Trainable params: 404,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwQzalUQLk2b"
      },
      "source": [
        "### 12.5.5 The generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VGhpwZIcLlyU"
      },
      "outputs": [],
      "source": [
        "# Listing 12.35 GAN generator network\n",
        "latent_dim = 128\n",
        "\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(8 * 8 * 128),\n",
        "        layers.Reshape((8, 8, 128)),\n",
        "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMS562uVLqSE",
        "outputId": "170b9aaa-f2e0-4ab7-d068-556a84ce5f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 8192)              1056768   \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      262272    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      524544    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 512)      2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 3)         38403     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,979,651\n",
            "Trainable params: 3,979,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFY2E6yHLu5n"
      },
      "source": [
        "### 12.5.6 The adversarial network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DceVo216L83b"
      },
      "outputs": [],
      "source": [
        "# Listing 12.36 The GAN Model\n",
        "import tensorflow as tf\n",
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, self.latent_dim))\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))],\n",
        "            axis=0\n",
        "        )\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(\n",
        "                self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(\n",
        "            zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\"d_loss\": self.d_loss_metric.result(),\n",
        "                \"g_loss\": self.g_loss_metric.result()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ucAfABcdMOJQ"
      },
      "outputs": [],
      "source": [
        "# Listing 12.37 A callback that samples generated images during training\n",
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        for i in range(self.num_img):\n",
        "            img = keras.utils.array_to_img(generated_images[i])\n",
        "            img.save(f\"generated_img_{epoch:03d}_{i}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEvulOWfMS_Q",
        "outputId": "4c3604f5-b388-492a-a611-54aab4bc876d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6332/6332 [==============================] - 1781s 281ms/step - d_loss: 0.6060 - g_loss: 1.3309\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52bc4ceb90>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Listing 12.38 Compiling and training the GAN\n",
        "epochs = 1\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDXCPaw2MWlp"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DeepLearning_book_12_5.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
