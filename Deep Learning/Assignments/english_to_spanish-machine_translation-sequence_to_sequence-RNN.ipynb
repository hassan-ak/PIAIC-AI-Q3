{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1gK60vg-UUI"
      },
      "source": [
        "# English to Spanish - Machine Translation - Sequence to sequence - RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzAiN27NuKAe",
        "outputId": "a511f33f-e2fc-4a4e-cfc5-e7c39afdd96f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-06-20 15:03:38--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.98.128, 74.125.197.128, 74.125.142.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.98.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2638744 (2.5M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "\rspa-eng.zip           0%[                    ]       0  --.-KB/s               \rspa-eng.zip         100%[===================>]   2.52M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-06-20 15:03:38 (232 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# English to spanish data base\n",
        "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
        "!unzip -q spa-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o4h7SNaHuUOT"
      },
      "outputs": [],
      "source": [
        "# parse the file\n",
        "text_file = \"spa-eng/spa.txt\"\n",
        "with open(text_file) as f:\n",
        "  lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = [] \n",
        "for line in lines:\n",
        "  english, spanish = line.split(\"\\t\")\n",
        "  spanish = \"[start] \" + spanish + \" [end]\"\n",
        "  text_pairs.append((english, spanish))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDhAtgT6ujmn",
        "outputId": "4a0c08f1-c79a-4541-ecf8-27a8915836cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('I want you to talk to Tom.', '[start] Quiero que hables con Tom. [end]')\n"
          ]
        }
      ],
      "source": [
        "# random data\n",
        "import random\n",
        "print(random.choice(text_pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CGXNNzgKuooL"
      },
      "outputs": [],
      "source": [
        "# Shuffle and split\n",
        "import random\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sD0L74s7vRpk"
      },
      "outputs": [],
      "source": [
        "# Listing 11.26 Vectorizing the English and Spanish text pairs\n",
        "import tensorflow as tf \n",
        "import string\n",
        "import re\n",
        "from tensorflow.keras import layers\n",
        " \n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "def custom_standardization(input_string):\n",
        "  lowercase = tf.strings.lower(input_string)\n",
        "  return tf.strings.regex_replace(\n",
        "      lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_spanish_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aL2TI79djNaO"
      },
      "outputs": [],
      "source": [
        "# Listing 11.27 Preparing datasets for the translation task\n",
        "batch_size = 64\n",
        " \n",
        "def format_dataset(eng, spa):\n",
        "  eng = source_vectorization(eng)\n",
        "  spa = target_vectorization(spa)\n",
        "  return ({\n",
        "      \"english\": eng,\n",
        "      \"spanish\": spa[:, :-1],\n",
        "      }, \n",
        "      spa[:, 1:]) \n",
        "  \n",
        "def make_dataset(pairs):\n",
        "  eng_texts, spa_texts = zip(*pairs)\n",
        "  eng_texts = list(eng_texts)\n",
        "  spa_texts = list(spa_texts)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.map(format_dataset, num_parallel_calls=1)\n",
        "  return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGR0Nm-Sj-Pd",
        "outputId": "460adb07-ec68-437b-bfd1-2dd40b72329b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs['english'].shape: (64, 20)\n",
            "inputs['spanish'].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "# dataset outputs look like\n",
        "for inputs, targets in train_ds.take(1):\n",
        "  print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
        "  print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
        "  print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4qMMrLXfntRT"
      },
      "outputs": [],
      "source": [
        "# Listing 11.28 GRU-based encoder\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        " \n",
        "embed_dim = 256\n",
        "latent_dim = 1024\n",
        "\n",
        "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
        "encoded_source = layers.Bidirectional(layers.GRU(latent_dim), merge_mode=\"sum\")(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hXFbznkNoBfV"
      },
      "outputs": [],
      "source": [
        "# Listing 11.29 GRU-based decoder and the end-to-end model\n",
        "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
        "decoder_gru = layers.GRU(latent_dim, return_sequences=True)\n",
        "x = decoder_gru(x, initial_state=encoded_source)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "seq2seq_rnn = keras.Model([source, past_target], target_next_step) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cr4t1Mcpigh",
        "outputId": "57b7ef07-99a1-48fb-fa86-c64032540830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " english (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " spanish (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 256)    3840000     ['english[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 256)    3840000     ['spanish[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 1024)         7876608     ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    (None, None, 1024)   3938304     ['embedding_1[0][0]',            \n",
            "                                                                  'bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, None, 1024)   0           ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 15000)  15375000    ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 34,869,912\n",
            "Trainable params: 34,869,912\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "seq2seq_rnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McxUL7wdoh8T",
        "outputId": "6afa25df-428f-4fb7-e9bd-2ad5390c61e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1302/1302 [==============================] - 134s 95ms/step - loss: 1.3238 - accuracy: 0.5257 - val_loss: 1.1519 - val_accuracy: 0.5683\n",
            "Epoch 2/5\n",
            "1302/1302 [==============================] - 120s 92ms/step - loss: 1.1777 - accuracy: 0.5757 - val_loss: 1.0752 - val_accuracy: 0.5984\n",
            "Epoch 3/5\n",
            "1302/1302 [==============================] - 119s 91ms/step - loss: 1.0858 - accuracy: 0.6077 - val_loss: 1.0350 - val_accuracy: 0.6179\n",
            "Epoch 4/5\n",
            "1302/1302 [==============================] - 119s 91ms/step - loss: 1.0377 - accuracy: 0.6323 - val_loss: 1.0208 - val_accuracy: 0.6293\n",
            "Epoch 5/5\n",
            "1302/1302 [==============================] - 119s 91ms/step - loss: 1.0074 - accuracy: 0.6506 - val_loss: 1.0171 - val_accuracy: 0.6355\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f93887f3dd0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Listing 11.30 Training our recurrent sequence-to-sequence model\n",
        "seq2seq_rnn.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "seq2seq_rnn.fit(train_ds, epochs=5, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHRBD_ztp8Hz",
        "outputId": "2286664c-0412-4fec-d90f-0a30779f0ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-\n",
            "I've corrected the mistake.\n",
            "[start] he [UNK] el error [end]\n",
            "-\n",
            "Something tells me Tom will be OK.\n",
            "[start] algo que me va a tom se está bien [end]\n",
            "-\n",
            "He saw the boy jump over the fence and run away.\n",
            "[start] Él vio a la [UNK] el [UNK] y se [UNK] a la [UNK] [end]\n",
            "-\n",
            "Why do the five yen coin and the fifty yen coin have holes in the center?\n",
            "[start] por qué los [UNK] la [UNK] y el [UNK] se [UNK] en el cinco de la [UNK] [end]\n",
            "-\n",
            "Tom visited Mary on October 20th.\n",
            "[start] tom le pasó a mary en el [UNK] de [UNK] de [UNK] [end]\n",
            "-\n",
            "We are teachers.\n",
            "[start] estamos [UNK] [end]\n",
            "-\n",
            "The explosion may have been caused by a gas leak.\n",
            "[start] la que se puede haber [UNK] un [UNK] de [UNK] [end]\n",
            "-\n",
            "I'm at the beach.\n",
            "[start] estoy en la playa [end]\n",
            "-\n",
            "Tom knows Mary won't tell John.\n",
            "[start] tom sabe que mary no se lo [UNK] a john [end]\n",
            "-\n",
            "Do you like to be alone?\n",
            "[start] te gusta estar solo [end]\n",
            "-\n",
            "Tell me what I should be watching for.\n",
            "[start] dime qué debería estar en punto [end]\n",
            "-\n",
            "What grade are you in?\n",
            "[start] qué estás haciendo [end]\n",
            "-\n",
            "Why do you want to work for our company?\n",
            "[start] por qué quieres hacer para nuestra casa [end]\n",
            "-\n",
            "He died last year.\n",
            "[start] murió el año pasado [end]\n",
            "-\n",
            "Would you stop babbling?\n",
            "[start] [UNK] de [UNK] [end]\n",
            "-\n",
            "He's a foreign exchange student.\n",
            "[start] Él es un estudiante de japonés [end]\n",
            "-\n",
            "The news took us by surprise.\n",
            "[start] las [UNK] nos [UNK] por él [end]\n",
            "-\n",
            "When I grow up, I want to be just like you.\n",
            "[start] cuando me quiero ser como tú [end]\n",
            "-\n",
            "There was no one in the room besides Tom and Mary.\n",
            "[start] no había una [UNK] en el cuarto de tom y mary [end]\n",
            "-\n",
            "I think you're the woman I've been waiting for all my life.\n",
            "[start] creo que eres la mujer que me [UNK] por todo el mundo [end]\n"
          ]
        }
      ],
      "source": [
        "# Listing 11.31 Translating new sentences with our RNN encoder and decoder\n",
        "import numpy as np\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "  tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "  decoded_sentence = \"[start]\" \n",
        "  for i in range(max_decoded_sentence_length):\n",
        "    tokenized_target_sentence = target_vectorization([decoded_sentence])\n",
        "    next_token_predictions = seq2seq_rnn.predict([tokenized_input_sentence, tokenized_target_sentence])\n",
        "    sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "    sampled_token = spa_index_lookup[sampled_token_index]\n",
        "    decoded_sentence += \" \" + sampled_token\n",
        "    if sampled_token == \"[end]\":\n",
        "      break\n",
        "  return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs] \n",
        "for _ in range(20):\n",
        "  input_sentence = random.choice(test_eng_texts)\n",
        "  print(\"-\")\n",
        "  print(input_sentence)\n",
        "  print(decode_sequence(input_sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DeepLearning_book_11_4.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
