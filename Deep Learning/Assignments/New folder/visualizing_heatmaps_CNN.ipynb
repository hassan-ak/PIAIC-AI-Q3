{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JQSM346lx28"
      },
      "source": [
        "# Visualizing heatmaps of class activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzBcB4EKpReV",
        "outputId": "327983b8-f345-43f4-9ee0-2911ccf5ede1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
            "91889664/91884032 [==============================] - 1s 0us/step\n",
            "91897856/91884032 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Listing 9.20 Loading the Xception network with pretrained weights\n",
        "model = keras.applications.xception.Xception(weights=\"imagenet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBhj7XmipaaU",
        "outputId": "b2d3fa38-0b53-49c1-881d-287d82889515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://img-datasets.s3.amazonaws.com/elephant.jpg\n",
            "737280/733657 [==============================] - 0s 0us/step\n",
            "745472/733657 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Listing 9.21 Preprocessing an input image for Xception\n",
        "img_path = keras.utils.get_file(\n",
        "    fname=\"elephant.jpg\",\n",
        "    origin=\"https://img-datasets.s3.amazonaws.com/elephant.jpg\")\n",
        "\n",
        "def get_img_array(img_path, target_size):\n",
        "  img = keras.utils.load_img(img_path, target_size=target_size)\n",
        "  array = keras.utils.img_to_array(img)\n",
        "  array = np.expand_dims(array, axis=0)\n",
        "  array = keras.applications.xception.preprocess_input(array)\n",
        "  return array\n",
        "\n",
        "img_array = get_img_array(img_path, target_size=(299, 299))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPWyLroapqKq",
        "outputId": "4d26f243-13f5-4858-be3f-4067a5f1813e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "49152/35363 [=========================================] - 0s 0us/step\n",
            "[('n02504458', 'African_elephant', 0.8699269), ('n01871265', 'tusker', 0.076968454), ('n02504013', 'Indian_elephant', 0.023537213)]\n"
          ]
        }
      ],
      "source": [
        "# run the pretrained network on the image and decode its prediction vector back to a human readable format\n",
        "preds = model.predict(img_array)\n",
        "print(keras.applications.xception.decode_predictions(preds, top=3)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXe-88Sgp4wI"
      },
      "outputs": [],
      "source": [
        "# Listing 9.22 Setting up a model that returns the last convolutional output\n",
        "last_conv_layer_name = \"block14_sepconv2_act\"\n",
        "classifier_layer_names = [\n",
        "    \"avg_pool\",\n",
        "    \"predictions\",\n",
        "]\n",
        "last_conv_layer = model.get_layer(last_conv_layer_name)\n",
        "last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwJDc83YqDQl"
      },
      "outputs": [],
      "source": [
        "# Listing 9.23 Reapplying the classifier on top of the last convolutional output\n",
        "classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "x = classifier_input \n",
        "for layer_name in classifier_layer_names:\n",
        "  x = model.get_layer(layer_name)(x)\n",
        "classifier_model = keras.Model(classifier_input, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA5H-ey9qJfx"
      },
      "outputs": [],
      "source": [
        "# Listing 9.24 Retrieving the gradients of the top predicted class\n",
        "import tensorflow as tf\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "    tape.watch(last_conv_layer_output)\n",
        "    preds = classifier_model(last_conv_layer_output)\n",
        "    top_pred_index = tf.argmax(preds[0])\n",
        "    top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "grads = tape.gradient(top_class_channel, last_conv_layer_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SXD9jjHqRf1"
      },
      "outputs": [],
      "source": [
        "# Listing 9.25 Gradient pooling and channel-importance weighting\n",
        "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2)).numpy()\n",
        "last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "for i in range(pooled_grads.shape[-1]):\n",
        "    last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "heatmap = np.mean(last_conv_layer_output, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "LOkKsVnCqX86",
        "outputId": "f968e924-4c1a-47dc-92e1-5887af81a338"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4839898710>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Listing 9.26 Heatmap post-processing\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "plt.matshow(heatmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msHaQOcpqbDn"
      },
      "outputs": [],
      "source": [
        "# Listing 9.27 Superimposing the heatmap on the original picture\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "img = keras.utils.load_img(img_path)\n",
        "img = keras.utils.img_to_array(img)\n",
        "\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "jet = cm.get_cmap(\"jet\")\n",
        "jet_colors = jet(np.arange(256))[:, :3]\n",
        "jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
        "jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
        "\n",
        "superimposed_img = jet_heatmap * 0.4 + img\n",
        "superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
        "\n",
        "save_path = \"elephant_cam.jpg\"\n",
        "superimposed_img.save(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoYJMEwitYAf"
      },
      "source": [
        "![](./visualizing_heatmaps_CNN-elephant_cam.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSfxvo_vY6uS"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Apuim3BNLuT8",
        "64pHKu97ZIGB"
      ],
      "name": "DeepLearning_book_9_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
